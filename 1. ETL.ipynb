{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. ETL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/06/2021-21:49:56 INFO: Starting ETL visualization\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import unicodedata\n",
    "\n",
    "#############################################\n",
    "# First data entries, visualization purposes\n",
    "#############################################\n",
    "\n",
    "print(\"{0} INFO: Starting ETL visualization\".format(datetime.datetime.now().strftime('%d/%m/%Y-%H:%M:%S')))\n",
    "\n",
    "# Read data entries\n",
    "df_accidents_2010 = pd.read_csv('Dataset/people_involved/2010_ACCIDENTS_PERSONES_GU_BCN_2010.csv', delimiter=',', encoding='latin1', decimal=\".\")\n",
    "df_accidents_2011 = pd.read_csv('Dataset/people_involved/2011_ACCIDENTS_PERSONES_GU_BCN_2011.csv', delimiter=',', encoding='latin1', decimal=\".\")\n",
    "df_accidents_2012 = pd.read_csv('Dataset/people_involved/2012_ACCIDENTS_PERSONES_GU_BCN_2012.csv', delimiter=',', encoding='latin1', decimal=\".\")\n",
    "df_accidents_2013 = pd.read_csv('Dataset/people_involved/2013_ACCIDENTS_PERSONES_GU_BCN_2013.csv', delimiter=',', encoding='latin1', decimal=\".\")\n",
    "df_accidents_2014 = pd.read_csv('Dataset/people_involved/2014_ACCIDENTS_PERSONES_GU_BCN_2014.csv', delimiter=',', encoding='latin1', decimal=\".\")\n",
    "df_accidents_2015 = pd.read_csv('Dataset/people_involved/2015_ACCIDENTS_PERSONES_GU_BCN_2015.csv', delimiter=',', encoding='latin1', decimal=\".\")\n",
    "df_accidents_2016 = pd.read_csv('Dataset/people_involved/2016_accidents_persones_gu_bcn.csv', delimiter=',', encoding='utf8', decimal=\".\")\n",
    "df_accidents_2017 = pd.read_csv('Dataset/people_involved/2017_accidents_persones_gu_bcn_.csv', delimiter=',', encoding='utf8', decimal=\".\")\n",
    "df_accidents_2018 = pd.read_csv('Dataset/people_involved/2018_accidents_persones_gu_bcn_.csv', delimiter=',', encoding='utf8', decimal=\".\")\n",
    "df_accidents_2019 = pd.read_csv('Dataset/people_involved/2019_accidents_persones_gu_bcn_.csv', delimiter=',', encoding='utf8', decimal=\".\")\n",
    "df_accidents_2020 = pd.read_csv('Dataset/people_involved/2020_accidents_persones_gu_bcn.csv', delimiter=',', encoding='utf8', decimal=\".\")\n",
    "\n",
    "# Prepare column names for homogenization\n",
    "df_accidents_2010.columns = df_accidents_2010.columns.str.strip().str.lower().str.replace(' ', '_').str.replace('(', '').str.replace(')', '').str.replace('ú', 'u').str.replace(\"d'\", '').str.replace('ó', 'o').str.replace('.', '').str.replace('_de_', '_')\n",
    "df_accidents_2011.columns = df_accidents_2011.columns.str.strip().str.lower().str.replace(' ', '_').str.replace('(', '').str.replace(')', '').str.replace('ú', 'u').str.replace(\"d'\", '').str.replace('ó', 'o').str.replace('.', '').str.replace('_de_', '_')\n",
    "df_accidents_2012.columns = df_accidents_2012.columns.str.strip().str.lower().str.replace(' ', '_').str.replace('(', '').str.replace(')', '').str.replace('ú', 'u').str.replace(\"d'\", '').str.replace('ó', 'o').str.replace('.', '').str.replace('_de_', '_')\n",
    "df_accidents_2013.columns = df_accidents_2013.columns.str.strip().str.lower().str.replace(' ', '_').str.replace('(', '').str.replace(')', '').str.replace('ú', 'u').str.replace(\"d'\", '').str.replace('ó', 'o').str.replace('.', '').str.replace('_de_', '_')\n",
    "df_accidents_2014.columns = df_accidents_2014.columns.str.strip().str.lower().str.replace(' ', '_').str.replace('(', '').str.replace(')', '').str.replace('£', 'u').str.replace('¢', 'o').str.replace(\"d'\", '').str.replace('.', '').str.replace('_de_', '_')\n",
    "df_accidents_2015.columns = df_accidents_2015.columns.str.strip().str.lower().str.replace(' ', '_').str.replace('(', '').str.replace(')', '').str.replace('ú', 'u').str.replace(\"d'\", '').str.replace('ó', 'o').str.replace('.', '').str.replace('_de_', '_')\n",
    "df_accidents_2016.columns = df_accidents_2016.columns.str.strip().str.lower().str.replace(' ', '_').str.replace('(', '').str.replace(')', '')\n",
    "df_accidents_2017.columns = df_accidents_2017.columns.str.strip().str.lower().str.replace(' ', '_').str.replace('(', '').str.replace(')', '').str.replace('__', '_')\n",
    "df_accidents_2018.columns = df_accidents_2018.columns.str.strip().str.lower().str.replace(' ', '_').str.replace('(', '').str.replace(')', '').str.replace('__', '_')\n",
    "df_accidents_2019.columns = df_accidents_2019.columns.str.strip().str.replace(' ', '_').str.replace('(', '').str.replace(')', '').str.replace('Ă§', 'c').str.replace('ç', 'c').str.replace('ó', 'o').str.lower().str.replace('.1', '').str.replace('__', '_')\n",
    "df_accidents_2020.columns = df_accidents_2020.columns.str.strip().str.replace(' ', '_').str.replace('(', '').str.replace(')', '').str.replace('Ă§', 'c').str.replace('ç', 'c').str.replace('ó', 'o').str.lower().str.replace('__', '_')\n",
    "\n",
    "df_accidents_2010.rename(columns={'nk_any': 'any'}, inplace=True)\n",
    "df_accidents_2011.rename(columns={'nk_any': 'any'}, inplace=True)\n",
    "df_accidents_2012.rename(columns={'nk_any': 'any'}, inplace=True)\n",
    "df_accidents_2013.rename(columns={'nk_any': 'any'}, inplace=True)\n",
    "df_accidents_2014.rename(columns={'nk_any': 'any'}, inplace=True)\n",
    "df_accidents_2015.rename(columns={'nk_any': 'any'}, inplace=True)\n",
    "df_accidents_2019.rename(columns={'nk_any': 'any'}, inplace=True)\n",
    "df_accidents_2020.rename(columns={'nk_any': 'any'}, inplace=True)\n",
    "\n",
    "# Drop useless columns and columns not present in all the history\n",
    "df_accidents_2010.drop(columns=['dia_setmana', 'descripcio_tipus_dia', 'descripcio_torn', 'num_postal_caption', 'nom_carrer', 'codi_carrer', 'descripcio_victimitzacio'], inplace=True)\n",
    "df_accidents_2011.drop(columns=['dia_setmana', 'descripcio_tipus_dia', 'descripcio_torn', 'num_postal_caption', 'nom_carrer', 'codi_carrer', 'descripcio_victimitzacio'], inplace=True)\n",
    "df_accidents_2012.drop(columns=['dia_setmana', 'descripcio_tipus_dia', 'descripcio_torn', 'num_postal_caption', 'nom_carrer', 'codi_carrer', 'descripcio_victimitzacio'], inplace=True)\n",
    "df_accidents_2013.drop(columns=['dia_setmana', 'descripcio_tipus_dia', 'descripcio_torn', 'num_postal_caption', 'nom_carrer', 'codi_carrer', 'descripcio_victimitzacio'], inplace=True)\n",
    "df_accidents_2014.drop(columns=['dia_setmana', 'descripcio_tipus_dia', 'num_postal_caption', 'nom_carrer', 'codi_carrer', 'descripcio_victimitzacio'], inplace=True)\n",
    "df_accidents_2015.drop(columns=['dia_setmana', 'descripcio_tipus_dia', 'num_postal_caption', 'nom_carrer', 'codi_carrer', 'descripcio_victimitzacio'], inplace=True)\n",
    "df_accidents_2016.drop(columns=['dia_setmana', 'descripcio_tipus_dia', 'descripcio_torn', 'num_postal', 'nom_carrer', 'codi_carrer', 'descripcio_situacio', 'descripcio_victimitzacio', 'longitud', 'latitud'], inplace=True)\n",
    "df_accidents_2017.drop(columns=['dia_setmana', 'descripcio_tipus_dia', 'descripcio_torn', 'num_postal', 'nom_carrer', 'codi_carrer', 'descripcio_situacio', 'descripcio_victimitzacio', 'longitud', 'latitud'], inplace=True)\n",
    "df_accidents_2018.drop(columns=['dia_setmana', 'descripcio_tipus_dia', 'descripcio_torn', 'num_postal', 'nom_carrer', 'codi_carrer', 'descripcio_situacio', 'descripcio_victimitzacio', 'longitud', 'latitud'], inplace=True)\n",
    "df_accidents_2019.drop(columns=['dia_setmana', 'descripcio_tipus_dia', 'descripcio_torn', 'num_postal', 'codi_carrer', 'descripcio_victimitzacio', 'descripcio_lloc_atropellament_vianat', 'descripcio_motiu_desplacament_vianant', 'descripcio_motiu_desplacament_conductor', 'longitud', 'latitud'], inplace=True)\n",
    "df_accidents_2020.drop(columns=['dia_setmana', 'descripcio_tipus_dia', 'descripcio_torn', 'num_postal', 'nom_carrer', 'codi_carrer', 'descripcio_victimitzacio', 'descripcio_motiu_desplacament_vianant', 'descripcio_motiu_desplacament_conductor', 'longitud', 'latitud', 'descripcio_lloc_atropellament_vianat'], inplace=True)\n",
    "\n",
    "# Sort columns alphabetically to match later on\n",
    "df_accidents_2010.sort_index(axis=1, inplace=True)\n",
    "df_accidents_2011.sort_index(axis=1, inplace=True)\n",
    "df_accidents_2012.sort_index(axis=1, inplace=True)\n",
    "df_accidents_2013.sort_index(axis=1, inplace=True)\n",
    "df_accidents_2014.sort_index(axis=1, inplace=True)\n",
    "df_accidents_2015.sort_index(axis=1, inplace=True)\n",
    "df_accidents_2016.sort_index(axis=1, inplace=True)\n",
    "df_accidents_2017.sort_index(axis=1, inplace=True)\n",
    "df_accidents_2018.sort_index(axis=1, inplace=True)\n",
    "df_accidents_2019.sort_index(axis=1, inplace=True)\n",
    "df_accidents_2020.sort_index(axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/06/2021-21:50:00 INFO: Ending ETL visualization\n"
     ]
    }
   ],
   "source": [
    "# Concat all columns now that the format is standard\n",
    "df_accidents_union_all = pd.concat([df_accidents_2010, df_accidents_2011, df_accidents_2012, df_accidents_2013, df_accidents_2014, df_accidents_2015, df_accidents_2016, df_accidents_2017, df_accidents_2018, df_accidents_2019, df_accidents_2020])\n",
    "\n",
    "# Remove accents and special character\n",
    "df_accidents_union_all['descripcio_causa_vianant'] = df_accidents_union_all['descripcio_causa_vianant'].str.normalize('NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8')\n",
    "df_accidents_union_all['desc_tipus_vehicle_implicat'] = df_accidents_union_all['desc_tipus_vehicle_implicat'].str.normalize('NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8')\n",
    "df_accidents_union_all['nom_barri'] = df_accidents_union_all['nom_barri'].str.normalize('NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8')\n",
    "df_accidents_union_all['nom_districte'] = df_accidents_union_all['nom_districte'].str.normalize('NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8')\n",
    "\n",
    "# Save the file\n",
    "df_accidents_union_all.to_csv('./accidents_homogenized_2010to2020.csv', index=False, header=True, encoding='utf-8')\n",
    "\n",
    "print(\"{0} INFO: Ending ETL visualization\".format(datetime.datetime.now().strftime('%d/%m/%Y-%H:%M:%S')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/06/2021-21:50:00 INFO: Function generate COVID-19 features\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Download Covid data restrictions from API\n",
    "def f_read_covid():\n",
    "    try:\n",
    "        # This part needs to be launch only one time, if we had more data on accidents we could update it more often\n",
    "        \"\"\"\n",
    "        df_covid = pd.read_csv('https://raw.githubusercontent.com/OxCGRT/covid-policy-tracker/master/data/OxCGRT_latest.csv')\n",
    "        df_covid.drop_duplicates(keep='first', inplace=True)\n",
    "        if 'ESP' in df_covid.CountryCode.unique():\n",
    "            df_covid = df_covid[df_covid.CountryCode == 'ESP']\n",
    "            df_covid.to_csv('./covid_feature.csv', index=False, header=True, encoding='utf-8')\n",
    "        \"\"\"\n",
    "        # If it was already generated we can simply read the file.\n",
    "        df_covid = pd.read_csv('./covid_feature.csv', delimiter=',', encoding='utf-8')\n",
    "    except Exception as e:\n",
    "        df_covid = None\n",
    "        print(\"{0} ERROR: retrieving covid data: {1}\".format(datetime.datetime.now().strftime('%d/%m/%Y-%H:%M:%S'), e))\n",
    "\n",
    "    # We took the columns only for the most relevant restrictions\n",
    "    col = ['Date', 'C2_Workplace closing', 'C3_Cancel public events',\n",
    "           'C4_Restrictions on gatherings', 'C6_Stay at home requirements',\n",
    "           'C7_Restrictions on internal movement']\n",
    "\n",
    "    df_covid = df_covid[col]\n",
    "\n",
    "    return df_covid\n",
    "\n",
    "\n",
    "# Generate the feature in a scale from 0 to 10\n",
    "# being 0 before Covid was discovered and 10 the highest restriction home quarantine\n",
    "def f_generate_covid_feature(p_df_covid):\n",
    "    print(\"{0} INFO: Function generate COVID-19 features\".format(datetime.datetime.now().strftime(\n",
    "        '%d/%m/%Y-%H:%M:%S')))\n",
    "    p_df_covid = p_df_covid.dropna().copy()\n",
    "    # Generate the final value giving more strength to restrictions affecting mobility\n",
    "    p_df_covid['COVID_VALUE'] = p_df_covid['C2_Workplace closing'] / 3 + p_df_covid['C3_Cancel public events'] / 6 + p_df_covid['C4_Restrictions on gatherings'] / 6 + p_df_covid['C6_Stay at home requirements'] + p_df_covid['C7_Restrictions on internal movement']\n",
    "    p_df_covid['COVID'] = 0\n",
    "\n",
    "    min_val = p_df_covid[p_df_covid.COVID_VALUE != 0].COVID_VALUE.min()\n",
    "    max_val = p_df_covid.COVID_VALUE.max()\n",
    "    param = (max_val - min_val) / 9\n",
    "    for i in range(9):\n",
    "        p_df_covid.loc[\n",
    "            (p_df_covid.COVID_VALUE >= min_val + i * param) & (p_df_covid.COVID_VALUE < min_val + (i + 1) * param), 'COVID'] = i + 1\n",
    "    p_df_covid.loc[p_df_covid.COVID_VALUE == max_val, 'COVID'] = 10\n",
    "    p_df_covid.loc[(p_df_covid.COVID_VALUE == 0) & (p_df_covid.Date < int('20200315')), 'COVID'] = 0\n",
    "\n",
    "    p_df_covid.drop(columns=['COVID_VALUE', 'C2_Workplace closing', 'C3_Cancel public events', 'C4_Restrictions on gatherings', 'C6_Stay at home requirements', 'C7_Restrictions on internal movement'], inplace=True)\n",
    "\n",
    "    return p_df_covid\n",
    "\n",
    "\n",
    "# Add covid feature\n",
    "df_feature_covid = f_read_covid()\n",
    "df_feature_covid = f_generate_covid_feature(df_feature_covid)\n",
    "\n",
    "# Merge section\n",
    "df_accidents_union_all['Full_Date'] = df_accidents_union_all['any'].map(str) + df_accidents_union_all['mes_any'].map(str).str.zfill(2) + df_accidents_union_all['dia_mes'].map(str).str.zfill(2)\n",
    "df_accidents_union_all['Full_Date'] = df_accidents_union_all['Full_Date'].astype(int)\n",
    "df_accidents_union_all = pd.merge(df_accidents_union_all, df_feature_covid, left_on=\"Full_Date\", right_on=\"Date\", how=\"left\", sort=False)\n",
    "df_accidents_union_all['COVID'] = df_accidents_union_all['COVID'].fillna(0)\n",
    "df_accidents_union_all.drop(columns=['Date', 'dia_mes', 'mes_any'], inplace=True)\n",
    "\n",
    "print(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/06/2021-21:50:00 INFO: Starting ETL predictions\n"
     ]
    }
   ],
   "source": [
    "#############################################\n",
    "# Second data entries, predictions purposes\n",
    "#############################################\n",
    "\n",
    "\n",
    "print(\"{0} INFO: Starting ETL predictions\".format(datetime.datetime.now().strftime('%d/%m/%Y-%H:%M:%S')))\n",
    "\n",
    "# Read data entries\n",
    "df_localpolice_2010 = pd.read_csv('Dataset/local_police/2010_ACCIDENTS_GU_BCN_2010.csv', delimiter=',', encoding='latin1')\n",
    "df_localpolice_2011 = pd.read_csv('Dataset/local_police/2011_ACCIDENTS_GU_BCN_2011.csv', delimiter=',', encoding='latin1')\n",
    "df_localpolice_2012 = pd.read_csv('Dataset/local_police/2012_ACCIDENTS_GU_BCN_2012.csv', delimiter=',', encoding='latin1')\n",
    "df_localpolice_2013 = pd.read_csv('Dataset/local_police/2013_ACCIDENTS_GU_BCN_2013.csv', delimiter=',', encoding='latin1')\n",
    "df_localpolice_2014 = pd.read_csv('Dataset/local_police/2014_ACCIDENTS_GU_BCN_2014.csv', delimiter=',', encoding='latin1')\n",
    "df_localpolice_2015 = pd.read_csv('Dataset/local_police/2015_accidents_gu_bcn.csv', delimiter=';', encoding='latin1')\n",
    "df_localpolice_2016 = pd.read_csv('Dataset/local_police/2016_accidents_gu_bcn.csv', delimiter=',', encoding='utf8')\n",
    "df_localpolice_2017 = pd.read_csv('Dataset/local_police/2017_accidents_gu_bcn.csv', delimiter=',', encoding='utf8')\n",
    "df_localpolice_2018 = pd.read_csv('Dataset/local_police/2018_accidents_gu_bcn.csv', delimiter=',', encoding='utf8')\n",
    "df_localpolice_2019 = pd.read_csv('Dataset/local_police/2019_accidents_gu_bcn.csv', delimiter=',', encoding='utf8')\n",
    "df_localpolice_2020 = pd.read_csv('Dataset/local_police/2020_accidents_gu_bcn.csv', delimiter=',', encoding='utf8')\n",
    "\n",
    "# Prepare column names for homogenization\n",
    "df_localpolice_2010.columns = df_localpolice_2010.columns.str.strip().str.lower().str.replace(' ', '_').str.replace('(', '').str.replace(')', '').str.replace('ú', 'u').str.replace(\"d'\", '').str.replace('ó', 'o').str.replace('.', '').str.replace('_de_', '_').str.replace('_caption', '').str.replace('_d_', '_').str.replace('í', 'i').str.replace('nk_barri', 'codi_barri')\n",
    "df_localpolice_2011.columns = df_localpolice_2011.columns.str.strip().str.lower().str.replace(' ', '_').str.replace('(', '').str.replace(')', '').str.replace('ú', 'u').str.replace(\"d'\", '').str.replace('ó', 'o').str.replace('.', '').str.replace('_de_', '_').str.replace('_caption', '').str.replace('_d_', '_').str.replace('í', 'i').str.replace('nk_barri', 'codi_barri')\n",
    "df_localpolice_2012.columns = df_localpolice_2012.columns.str.strip().str.lower().str.replace(' ', '_').str.replace('(', '').str.replace(')', '').str.replace('ú', 'u').str.replace(\"d'\", '').str.replace('ó', 'o').str.replace('.', '').str.replace('_de_', '_').str.replace('_caption', '').str.replace('_d_', '_').str.replace('í', 'i').str.replace('nk_barri', 'codi_barri')\n",
    "df_localpolice_2013.columns = df_localpolice_2013.columns.str.strip().str.lower().str.replace(' ', '_').str.replace('(', '').str.replace(')', '').str.replace('ú', 'u').str.replace(\"d'\", '').str.replace('ó', 'o').str.replace('.', '').str.replace('_de_', '_').str.replace('_caption', '').str.replace('_d_', '_').str.replace('í', 'i').str.replace('nk_barri', 'codi_barri')\n",
    "df_localpolice_2014.columns = df_localpolice_2014.columns.str.strip().str.lower().str.replace(' ', '_').str.replace('(', '').str.replace(')', '').str.replace('£', 'u').str.replace('¢', 'o').str.replace(\"d'\", '').str.replace('.', '').str.replace('_de_', '_').str.replace('ú', 'u').str.replace('ó', 'o').str.replace('_caption', '').str.replace('_d_', '_').str.replace('í', 'i').str.replace('nk_barri', 'codi_barri')\n",
    "df_localpolice_2015.columns = df_localpolice_2015.columns.str.strip().str.lower().str.replace(' ', '_').str.replace('(', '').str.replace(')', '').str.replace('ú', 'u').str.replace(\"d'\", '').str.replace('ó', 'o').str.replace('.', '').str.replace('_de_', '_').str.replace('_caption', '').str.replace('_d_', '_').str.replace('í', 'i').str.replace('nk_barri', 'codi_barri')\n",
    "df_localpolice_2016.columns = df_localpolice_2016.columns.str.strip().str.lower().str.replace(' ', '_').str.replace('(', '').str.replace(')', '').str.replace('ú', 'u').str.replace('ó', 'o').str.replace('_caption', '').str.replace('_d_', '_').str.replace('í', 'i').str.replace('nk_barri', 'codi_barri')\n",
    "df_localpolice_2017.columns = df_localpolice_2017.columns.str.strip().str.lower().str.replace(' ', '_').str.replace('(', '').str.replace(')', '').str.replace('__', '_').str.replace('ú', 'u').str.replace('ó', 'o').str.replace('_caption', '').str.replace('_d_', '_').str.replace('í', 'i').str.replace('nk_barri', 'codi_barri')\n",
    "df_localpolice_2018.columns = df_localpolice_2018.columns.str.strip().str.lower().str.replace(' ', '_').str.replace('(', '').str.replace(')', '').str.replace('__', '_').str.replace('ú', 'u').str.replace('ó', 'o').str.replace('_caption', '').str.replace('_d_', '_').str.replace('í', 'i').str.replace('nk_barri', 'codi_barri')\n",
    "df_localpolice_2019.columns = df_localpolice_2019.columns.str.strip().str.replace(' ', '_').str.replace('(', '').str.replace(')', '').str.replace('Ă§', 'c').str.replace('ç', 'c').str.replace('ó', 'o').str.lower().str.replace('.1', '').str.replace('__', '_').str.replace('ú', 'u').str.replace('_caption', '').str.replace('_d_', '_').str.replace('í', 'i').str.replace('nk_barri', 'codi_barri')\n",
    "df_localpolice_2020.columns = df_localpolice_2020.columns.str.strip().str.replace(' ', '_').str.replace('(', '').str.replace(')', '').str.replace('Ă§', 'c').str.replace('ç', 'c').str.replace('ó', 'o').str.lower().str.replace('__', '_').str.replace('ú', 'u').str.replace('_caption', '').str.replace('_d_', '_').str.replace('í', 'i').str.replace('nk_barri', 'codi_barri')\n",
    "\n",
    "df_localpolice_2015['dia_setmana'] = df_localpolice_2015['dia_setmana'].str.replace('Dl', '1').str.replace('Dm', '2').str.replace('Dc', '3').str.replace('Dj', '4').str.replace('Dv', '5').str.replace('Ds', '6').str.replace('Dg', '7')\n",
    "df_localpolice_2016['dia_setmana'] = df_localpolice_2016['dia_setmana'].str.replace('Dl', '1').str.replace('Dm', '2').str.replace('Dc', '3').str.replace('Dj', '4').str.replace('Dv', '5').str.replace('Ds', '6').str.replace('Dg', '7')\n",
    "df_localpolice_2017['dia_setmana'] = df_localpolice_2017['dia_setmana'].str.replace('Dl', '1').str.replace('Dm', '2').str.replace('Dc', '3').str.replace('Dj', '4').str.replace('Dv', '5').str.replace('Ds', '6').str.replace('Dg', '7')\n",
    "df_localpolice_2018['dia_setmana'] = df_localpolice_2018['dia_setmana'].str.replace('Dl', '1').str.replace('Dm', '2').str.replace('Dc', '3').str.replace('Dj', '4').str.replace('Dv', '5').str.replace('Ds', '6').str.replace('Dg', '7')\n",
    "df_localpolice_2019['dia_setmana'] = df_localpolice_2019['dia_setmana'].str.replace('Dl', '1').str.replace('Dm', '2').str.replace('Dc', '3').str.replace('Dj', '4').str.replace('Dv', '5').str.replace('Ds', '6').str.replace('Dg', '7')\n",
    "\n",
    "\n",
    "df_localpolice_2010.rename(columns={'nk_any': 'any'}, inplace=True)\n",
    "df_localpolice_2011.rename(columns={'nk_any': 'any'}, inplace=True)\n",
    "df_localpolice_2012.rename(columns={'nk_any': 'any'}, inplace=True)\n",
    "df_localpolice_2013.rename(columns={'nk_any': 'any'}, inplace=True)\n",
    "df_localpolice_2014.rename(columns={'nk_any': 'any'}, inplace=True)\n",
    "df_localpolice_2015.rename(columns={'nk_any': 'any'}, inplace=True)\n",
    "df_localpolice_2019.rename(columns={'nk_any': 'any'}, inplace=True)\n",
    "df_localpolice_2020.rename(columns={'nk_any': 'any'}, inplace=True)\n",
    "\n",
    "\n",
    "# Drop useless columns and columns not present in all the history\n",
    "df_localpolice_2010.drop(columns=[\"num_postal\", \"descripcio_dia_setmana\", \"descripcio_tipus_dia\", \"descripcio_torn\", \"nom_mes\"], inplace=True)\n",
    "df_localpolice_2011.drop(columns=[\"num_postal\", \"descripcio_dia_setmana\", \"descripcio_tipus_dia\", \"descripcio_torn\", \"nom_mes\"], inplace=True)\n",
    "df_localpolice_2012.drop(columns=[\"num_postal\", \"descripcio_dia_setmana\", \"descripcio_tipus_dia\", \"descripcio_torn\", \"nom_mes\"], inplace=True)\n",
    "df_localpolice_2013.drop(columns=[\"num_postal\", \"descripcio_dia_setmana\", \"descripcio_tipus_dia\", \"descripcio_torn\", \"nom_mes\"], inplace=True)\n",
    "df_localpolice_2014.drop(columns=[\"num_postal\", \"descripcio_dia_setmana\", \"descripcio_tipus_dia\", \"descripcio_torn\", \"nom_mes\"], inplace=True)\n",
    "df_localpolice_2015.drop(columns=[\"num_postal\", \"descripcio_dia_setmana\", \"descripcio_tipus_dia\", \"descripcio_torn\", \"nom_mes\"], inplace=True)\n",
    "df_localpolice_2016.drop(columns=['latitud', 'longitud', \"num_postal\", \"descripcio_dia_setmana\", \"descripcio_tipus_dia\", \"descripcio_torn\", \"nom_mes\"], inplace=True)\n",
    "df_localpolice_2017.drop(columns=['latitud', 'longitud', \"num_postal\", \"descripcio_dia_setmana\", \"descripcio_tipus_dia\", \"descripcio_torn\", \"nom_mes\"], inplace=True)\n",
    "df_localpolice_2018.drop(columns=['latitud', 'longitud', \"num_postal\", \"descripcio_dia_setmana\", \"descripcio_tipus_dia\", \"descripcio_torn\", \"nom_mes\"], inplace=True)\n",
    "df_localpolice_2019.drop(columns=['latitud', 'longitud', \"num_postal\", \"descripcio_dia_setmana\", \"descripcio_tipus_dia\", \"descripcio_torn\", \"nom_mes\"], inplace=True)\n",
    "df_localpolice_2020.drop(columns=['latitud', 'longitud', \"num_postal\", \"descripcio_dia_setmana\", \"descripcio_tipus_dia\", \"descripcio_torn\", \"nom_mes\"], inplace=True)\n",
    "\n",
    "\n",
    "# Sort columns alphabetically to match later on\n",
    "df_localpolice_2010.sort_index(axis=1, inplace=True)\n",
    "df_localpolice_2011.sort_index(axis=1, inplace=True)\n",
    "df_localpolice_2012.sort_index(axis=1, inplace=True)\n",
    "df_localpolice_2013.sort_index(axis=1, inplace=True)\n",
    "df_localpolice_2014.sort_index(axis=1, inplace=True)\n",
    "df_localpolice_2015.sort_index(axis=1, inplace=True)\n",
    "df_localpolice_2016.sort_index(axis=1, inplace=True)\n",
    "df_localpolice_2017.sort_index(axis=1, inplace=True)\n",
    "df_localpolice_2018.sort_index(axis=1, inplace=True)\n",
    "df_localpolice_2019.sort_index(axis=1, inplace=True)\n",
    "df_localpolice_2020.sort_index(axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concat all columns now that the format is standard\n",
    "df_localpolice_union_all = pd.concat([df_localpolice_2010, df_localpolice_2011, df_localpolice_2012, df_localpolice_2013, df_localpolice_2014, df_localpolice_2015, df_localpolice_2016, df_localpolice_2017, df_localpolice_2018, df_localpolice_2019, df_localpolice_2020])\n",
    "\n",
    "\n",
    "# Remove accents and special character\n",
    "df_localpolice_union_all['descripcio_causa_vianant'] = df_localpolice_union_all['descripcio_causa_vianant'].str.normalize('NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8')\n",
    "df_localpolice_union_all['nom_barri'] = df_localpolice_union_all['nom_barri'].str.normalize('NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8')\n",
    "df_localpolice_union_all['nom_districte'] = df_localpolice_union_all['nom_districte'].str.normalize('NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8')\n",
    "\n",
    "# merge any\n",
    "df_localpolice_union_all['any'] = df_localpolice_union_all['any'].astype(str)\n",
    "df_localpolice_union_all['mes_any'] = df_localpolice_union_all['mes_any'].astype(int)\n",
    "df_localpolice_union_all['dia_mes'] = df_localpolice_union_all['dia_mes'].astype(int)\n",
    "df_localpolice_union_all['Full_Date'] = df_localpolice_union_all['any'].map(str) + df_localpolice_union_all['mes_any'].map(str).str.zfill(2) + df_localpolice_union_all['dia_mes'].map(str).str.zfill(2)\n",
    "df_localpolice_union_all['Full_Date'] = df_localpolice_union_all['Full_Date'].astype(int)\n",
    "\n",
    "# Merge section\n",
    "df_localpolice_union_all['Full_Date'] = df_localpolice_union_all['any'].map(str) + df_localpolice_union_all['mes_any'].map(str).str.zfill(2) + df_localpolice_union_all['dia_mes'].map(str).str.zfill(2)\n",
    "df_localpolice_union_all['Full_Date'] = df_localpolice_union_all['Full_Date'].astype(int)\n",
    "df_localpolice_union_all = pd.merge(df_localpolice_union_all, df_feature_covid, left_on=\"Full_Date\", right_on=\"Date\", how=\"left\", sort=False)\n",
    "df_localpolice_union_all['COVID'] = df_localpolice_union_all['COVID'].fillna(0)\n",
    "\n",
    "df_localpolice_union_all.drop(columns=['Date'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/06/2021-21:50:02 INFO: Ending ETL predictions\n"
     ]
    }
   ],
   "source": [
    "# Save the file\n",
    "df_localpolice_union_all.to_csv('./accidents_localpolice_homogenized_2010to2020.csv', index=False, header=True, encoding='utf-8')\n",
    "\n",
    "print(\"{0} INFO: Ending ETL predictions\".format(datetime.datetime.now().strftime('%d/%m/%Y-%H:%M:%S')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
